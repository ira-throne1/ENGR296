{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8d70709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ira/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ira/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ira/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "2023-12-07 10:17:07.863082: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-07 10:17:07.864174: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-07 10:17:07.885924: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-07 10:17:07.886378: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-07 10:17:08.277061: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0f39aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('completeSpamAssassin.csv', delimiter=',')\n",
    "df2 = pd.read_csv('emailsStudyMartOwner.csv', delimiter=',')\n",
    "df3 = pd.read_csv('enronSpamSubset.csv', delimiter=',')\n",
    "df4 = pd.read_csv('spam_ham_datasetYashpal.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8620c50",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "### Consolidating the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1eb9c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0                                               Body  Label\n",
      "0              0  \\nSave up to 70% on Life Insurance.\\nWhy Spend...      1\n",
      "1              1  1) Fight The Risk of Cancer!\\nhttp://www.adcli...      1\n",
      "2              2  1) Fight The Risk of Cancer!\\nhttp://www.adcli...      1\n",
      "3              3  ##############################################...      1\n",
      "4              4  I thought you might like these:\\n1) Slim Down ...      1\n",
      "...          ...                                                ...    ...\n",
      "6041        6041                                              empty      0\n",
      "6042        6042                    ___           ___           ...      0\n",
      "6043        6043  IN THIS ISSUE:01. Readers write\\n02. Extension...      0\n",
      "6044        6044                                              empty      0\n",
      "6045        6045                                              empty      0\n",
      "\n",
      "[6046 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd25370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nSave up to 70% on Life Insurance.\\nWhy Spend...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1) Fight The Risk of Cancer!\\nhttp://www.adcli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1) Fight The Risk of Cancer!\\nhttp://www.adcli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>##############################################...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I thought you might like these:\\n1) Slim Down ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Body  Label\n",
       "0  \\nSave up to 70% on Life Insurance.\\nWhy Spend...      1\n",
       "1  1) Fight The Risk of Cancer!\\nhttp://www.adcli...      1\n",
       "2  1) Fight The Risk of Cancer!\\nhttp://www.adcli...      1\n",
       "3  ##############################################...      1\n",
       "4  I thought you might like these:\\n1) Slim Down ...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1.drop(df1.columns[0], axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae9ad94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text spam Unnamed: 2  \\\n",
      "0     Subject: naturally irresistible your corporate...    1        NaN   \n",
      "1     Subject: the stock trading gunslinger  fanny i...    1        NaN   \n",
      "2     Subject: unbelievable new homes made easy  im ...    1        NaN   \n",
      "3     Subject: 4 color printing special  request add...    1        NaN   \n",
      "4     Subject: do not have money , get software cds ...    1        NaN   \n",
      "...                                                 ...  ...        ...   \n",
      "5725  Subject: re : research and development charges...    0        NaN   \n",
      "5726  Subject: re : receipts from visit  jim ,  than...    0        NaN   \n",
      "5727  Subject: re : enron case study update  wow ! a...    0        NaN   \n",
      "5728  Subject: re : interest  david ,  please , call...    0        NaN   \n",
      "5729  Subject: news : aurora 5 . 2 update  aurora ve...    0        NaN   \n",
      "\n",
      "     Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8  \\\n",
      "0           NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "1           NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "2           NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "3           NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "4           NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "5725        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "5726        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "5727        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "5728        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "5729        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "\n",
      "     Unnamed: 9  ... Unnamed: 100 Unnamed: 101 Unnamed: 102 Unnamed: 103  \\\n",
      "0           NaN  ...          NaN          NaN          NaN          NaN   \n",
      "1           NaN  ...          NaN          NaN          NaN          NaN   \n",
      "2           NaN  ...          NaN          NaN          NaN          NaN   \n",
      "3           NaN  ...          NaN          NaN          NaN          NaN   \n",
      "4           NaN  ...          NaN          NaN          NaN          NaN   \n",
      "...         ...  ...          ...          ...          ...          ...   \n",
      "5725        NaN  ...          NaN          NaN          NaN          NaN   \n",
      "5726        NaN  ...          NaN          NaN          NaN          NaN   \n",
      "5727        NaN  ...          NaN          NaN          NaN          NaN   \n",
      "5728        NaN  ...          NaN          NaN          NaN          NaN   \n",
      "5729        NaN  ...          NaN          NaN          NaN          NaN   \n",
      "\n",
      "     Unnamed: 104 Unnamed: 105 Unnamed: 106 Unnamed: 107 Unnamed: 108  \\\n",
      "0             NaN          NaN          NaN          NaN          NaN   \n",
      "1             NaN          NaN          NaN          NaN          NaN   \n",
      "2             NaN          NaN          NaN          NaN          NaN   \n",
      "3             NaN          NaN          NaN          NaN          NaN   \n",
      "4             NaN          NaN          NaN          NaN          NaN   \n",
      "...           ...          ...          ...          ...          ...   \n",
      "5725          NaN          NaN          NaN          NaN          NaN   \n",
      "5726          NaN          NaN          NaN          NaN          NaN   \n",
      "5727          NaN          NaN          NaN          NaN          NaN   \n",
      "5728          NaN          NaN          NaN          NaN          NaN   \n",
      "5729          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "     Unnamed: 109  \n",
      "0             NaN  \n",
      "1             NaN  \n",
      "2             NaN  \n",
      "3             NaN  \n",
      "4             NaN  \n",
      "...           ...  \n",
      "5725          NaN  \n",
      "5726          NaN  \n",
      "5727          NaN  \n",
      "5728          NaN  \n",
      "5729          NaN  \n",
      "\n",
      "[5730 rows x 110 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6b64940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Body Label\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.iloc[:, :2]\n",
    "df2 = df2.rename(columns={'text': 'Body', 'spam': 'Label'})\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eda70460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0.1  Unnamed: 0  \\\n",
      "0             2469        2469   \n",
      "1             5063        5063   \n",
      "2            12564       12564   \n",
      "3             2796        2796   \n",
      "4             1468        1468   \n",
      "...            ...         ...   \n",
      "9995         26222       26222   \n",
      "9996         18630       18630   \n",
      "9997         18451       18451   \n",
      "9998         21955       21955   \n",
      "9999         32062       32062   \n",
      "\n",
      "                                                   Body  Label  \n",
      "0     Subject: stock promo mover : cwtd\\n * * * urge...      1  \n",
      "1     Subject: are you listed in major search engine...      1  \n",
      "2     Subject: important information thu , 30 jun 20...      1  \n",
      "3     Subject: = ? utf - 8 ? q ? bask your life with...      1  \n",
      "4     Subject: \" bidstogo \" is places to go , things...      1  \n",
      "...                                                 ...    ...  \n",
      "9995  Subject: monday 22 nd oct\\n louise ,\\n do you ...      0  \n",
      "9996  Subject: missing bloomberg deals\\n stephanie -...      0  \n",
      "9997  Subject: eops salary survey questionnaire\\n we...      0  \n",
      "9998  Subject: q 3 comparison\\n hi louise ,\\n i have...      0  \n",
      "9999  Subject: confidential folder to safely pass in...      0  \n",
      "\n",
      "[10000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6df4b01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: stock promo mover : cwtd\\n * * * urge...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: are you listed in major search engine...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: important information thu , 30 jun 20...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: = ? utf - 8 ? q ? bask your life with...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: \" bidstogo \" is places to go , things...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Body  Label\n",
       "0  Subject: stock promo mover : cwtd\\n * * * urge...      1\n",
       "1  Subject: are you listed in major search engine...      1\n",
       "2  Subject: important information thu , 30 jun 20...      1\n",
       "3  Subject: = ? utf - 8 ? q ? bask your life with...      1\n",
       "4  Subject: \" bidstogo \" is places to go , things...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df3.drop(df3.columns[[0, 1]], axis=1)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61a417eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0 label                                               text  \\\n",
      "0            605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
      "1           2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
      "2           3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
      "3           4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
      "4           2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
      "...          ...   ...                                                ...   \n",
      "5166        1518   ham  Subject: put the 10 on the ft\\r\\nthe transport...   \n",
      "5167         404   ham  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...   \n",
      "5168        2933   ham  Subject: calpine daily gas nomination\\r\\n>\\r\\n...   \n",
      "5169        1409   ham  Subject: industrial worksheets for august 2000...   \n",
      "5170        4807  spam  Subject: important online banking alert\\r\\ndea...   \n",
      "\n",
      "      label_num  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             1  \n",
      "4             0  \n",
      "...         ...  \n",
      "5166          0  \n",
      "5167          0  \n",
      "5168          0  \n",
      "5169          0  \n",
      "5170          1  \n",
      "\n",
      "[5171 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e21e3481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Body  Label\n",
       "0  Subject: enron methanol ; meter # : 988291\\r\\n...      0\n",
       "1  Subject: hpl nom for january 9 , 2001\\r\\n( see...      0\n",
       "2  Subject: neon retreat\\r\\nho ho ho , we ' re ar...      0\n",
       "3  Subject: photoshop , windows , office . cheap ...      1\n",
       "4  Subject: re : indian springs\\r\\nthis deal is t...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = df4.drop(df4.columns[[0, 1]], axis=1)\n",
    "df4 = df4.rename(columns={'text': 'Body', 'label_num': 'Label'})\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0bd59d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    Body Label\n",
      "0      \\nSave up to 70% on Life Insurance.\\nWhy Spend...     1\n",
      "1      1) Fight The Risk of Cancer!\\nhttp://www.adcli...     1\n",
      "2      1) Fight The Risk of Cancer!\\nhttp://www.adcli...     1\n",
      "3      ##############################################...     1\n",
      "4      I thought you might like these:\\n1) Slim Down ...     1\n",
      "...                                                  ...   ...\n",
      "26942  Subject: put the 10 on the ft\\r\\nthe transport...     0\n",
      "26943  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...     0\n",
      "26944  Subject: calpine daily gas nomination\\r\\n>\\r\\n...     0\n",
      "26945  Subject: industrial worksheets for august 2000...     0\n",
      "26946  Subject: important online banking alert\\r\\ndea...     1\n",
      "\n",
      "[26947 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df1, df2.iloc[:, :], df3.iloc[:, :], df4.iloc[:, :]], ignore_index=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c032d53d",
   "metadata": {},
   "source": [
    "### Cleaning up the Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28568432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure all labels are in the same format\n",
    "df['Label'] = pd.to_numeric(df['Label'], errors='coerce')\n",
    "df = df.dropna(subset=['Label'])\n",
    "df['Label'] = df['Label'].astype(int)\n",
    "\n",
    "# Removing 'noise' from the texts\n",
    "df['Body'] = df['Body'].astype(str)\n",
    "df['Body'] = df['Body'].str.lower()\n",
    "df['Body'] = df['Body'].str.replace('^subject: ', '', regex=True)\n",
    "df['Body'] = df['Body'].str.replace('\\n', ' ',)\n",
    "df['Body'] = df['Body'].str.replace('\\r', ' ',)\n",
    "df['Body'] = df['Body'].str.replace('^re:', '',)\n",
    "df['Body'] = df['Body'].str.replace('^re :', '', regex=True)\n",
    "df['Body'] = df['Body'].str.replace(' re :', '')\n",
    "df['Body'] = df['Body'].str.replace('^fw:', '',)\n",
    "df['Body'] = df['Body'].str.replace('^fw :', '', regex=True)\n",
    "df['Body'] = df['Body'].str.replace(' fw :', '')\n",
    "df['Body'] = df['Body'].str.replace('^url:', '', regex=True)\n",
    "# removing URL's\n",
    "df['Body'] = df['Body'].str.replace(r'(http[s]?://|www\\.)\\S+', '', regex=True)\n",
    "# removing email addresses\n",
    "df['Body'] = df['Body'].str.replace(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}', '', regex=True)\n",
    "\n",
    "# removing non alphanumeric and non-punctuation characters\n",
    "df['Body'] = df['Body'].str.replace(r'[^a-z0-9,.:;\\'`\\-?!()&]', ' ', regex=True)\n",
    "# removing extra spaces\n",
    "df['Body'] = df['Body'].str.replace(r'\\s+', ' ', regex=True)\n",
    "df['Body'] = df['Body'].str.replace('^ ', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d680a59",
   "metadata": {},
   "source": [
    "### Removing Unnecessary Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71822677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "\n",
    "# creating a copy of the dataframe with only alphanumeric characters\n",
    "df_plain = df\n",
    "df_plain['Body'] = df_plain['Body'].str.replace(r'[^a-z0-9]', ' ', regex=True)\n",
    "df_plain['Body'] = df_plain['Body'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "def is_subset_of_other_email(email, email_series):\n",
    "    for other_email in email_series:\n",
    "        if email != other_email and email in other_email:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "mask = df_plain['Body'].apply(lambda x: not is_subset_of_other_email(x, df_plain['Body']))\n",
    "#Use the mask to filter the DataFrame\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4e65db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20472, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing entries with no text\n",
    "df = df[df['Body'] != 'empty']\n",
    "df = df[df['Body'] != '']\n",
    "df = df.dropna(subset=['Body'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdfd638",
   "metadata": {},
   "source": [
    "### Spam to Ham Numbers and Proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c07e5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_counts = df['Label'].value_counts()\n",
    "plt.bar(label_counts.index, label_counts.values)\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Labels in the Dataset')\n",
    "plt.xticks([0, 1])  # Set x-ticks to be the labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee2b2fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Counts Percentage\n",
      "Label                   \n",
      "0       12849     62.76%\n",
      "1        7623     37.24%\n"
     ]
    }
   ],
   "source": [
    "spam_counts = df['Label'].value_counts()\n",
    "spam_percent = df['Label'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%'\n",
    "print(pd.concat([spam_counts, spam_percent], axis=1, keys=['Counts', 'Percentage']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac45188f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20472, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffling the entries\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "872b6947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    Body  Label\n",
      "0      also available levitra cialis and viagra keepi...      1\n",
      "1      calpine monthly nomination forwarded by aimee ...      0\n",
      "2      john p looney wrote on thu aug 22 2002 at 05 1...      0\n",
      "3       no subject stinson henwood can help us with t...      0\n",
      "4      lose 19 weight new weightloss available to you...      1\n",
      "...                                                  ...    ...\n",
      "20467  now i know bundle famish welcome varou the gra...      1\n",
      "20468  new line item f y i japanese electricity is th...      0\n",
      "20469  new turn on range resources vance a ticket has...      0\n",
      "20470  use perl daily headline mailerspouses afternoo...      0\n",
      "20471  powerisk 2001 your invitation angelika thanks ...      0\n",
      "\n",
      "[20472 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c532fddd",
   "metadata": {},
   "source": [
    "# Further Preparations\n",
    "### Vectorizing the Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdaacb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "      <th>Preproc_txt</th>\n",
       "      <th>Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also available levitra cialis and viagra keepi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[also, available, levitra, cialis, viagra, kee...</td>\n",
       "      <td>[1.6163436, 2.1998005, 0.84823847, -0.9715893,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>calpine monthly nomination forwarded by aimee ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[calpine, monthly, nomination, forwarded, aime...</td>\n",
       "      <td>[1.0151408, 0.62459177, 0.26562575, -1.0730993...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>john p looney wrote on thu aug 22 2002 at 05 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>[john, p, looney, wrote, thu, aug, 22, 2002, 0...</td>\n",
       "      <td>[0.87613297, 0.3476915, 0.85935056, -0.5140939...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no subject stinson henwood can help us with t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[subject, stinson, henwood, help, u, project, ...</td>\n",
       "      <td>[2.1047955, 1.7402498, -0.3284932, 0.095167555...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lose 19 weight new weightloss available to you...</td>\n",
       "      <td>1</td>\n",
       "      <td>[lose, 19, weight, new, weightloss, available,...</td>\n",
       "      <td>[1.041842, 0.69830966, -1.3863869, -0.9889647,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hpl nom for march 9 2001 see attached file hpl...</td>\n",
       "      <td>0</td>\n",
       "      <td>[hpl, nom, march, 9, 2001, see, attached, file...</td>\n",
       "      <td>[1.4207256, 1.6403165, 0.9553901, -0.5626389, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nova psp disponivel ja so na springshop inform...</td>\n",
       "      <td>1</td>\n",
       "      <td>[nova, psp, disponivel, ja, na, springshop, in...</td>\n",
       "      <td>[1.6428739, -0.11459401, -0.6236425, -1.565189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>date not suppliedtechnical problems beat a tra...</td>\n",
       "      <td>0</td>\n",
       "      <td>[date, suppliedtechnical, problem, beat, trans...</td>\n",
       "      <td>[1.090038, 1.1250864, 1.4104717, 0.7268404, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>grep for windows folks those of you who have u...</td>\n",
       "      <td>0</td>\n",
       "      <td>[grep, window, folk, used, unix, probably, fam...</td>\n",
       "      <td>[2.1363153, 0.7653812, 0.08830727, -0.54238415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>february production estimate forwarded by carl...</td>\n",
       "      <td>0</td>\n",
       "      <td>[february, production, estimate, forwarded, ca...</td>\n",
       "      <td>[0.18950234, 0.67726636, 0.48134622, -1.469822...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Body  Label  \\\n",
       "0  also available levitra cialis and viagra keepi...      1   \n",
       "1  calpine monthly nomination forwarded by aimee ...      0   \n",
       "2  john p looney wrote on thu aug 22 2002 at 05 1...      0   \n",
       "3   no subject stinson henwood can help us with t...      0   \n",
       "4  lose 19 weight new weightloss available to you...      1   \n",
       "5  hpl nom for march 9 2001 see attached file hpl...      0   \n",
       "6  nova psp disponivel ja so na springshop inform...      1   \n",
       "7  date not suppliedtechnical problems beat a tra...      0   \n",
       "8  grep for windows folks those of you who have u...      0   \n",
       "9  february production estimate forwarded by carl...      0   \n",
       "\n",
       "                                         Preproc_txt  \\\n",
       "0  [also, available, levitra, cialis, viagra, kee...   \n",
       "1  [calpine, monthly, nomination, forwarded, aime...   \n",
       "2  [john, p, looney, wrote, thu, aug, 22, 2002, 0...   \n",
       "3  [subject, stinson, henwood, help, u, project, ...   \n",
       "4  [lose, 19, weight, new, weightloss, available,...   \n",
       "5  [hpl, nom, march, 9, 2001, see, attached, file...   \n",
       "6  [nova, psp, disponivel, ja, na, springshop, in...   \n",
       "7  [date, suppliedtechnical, problem, beat, trans...   \n",
       "8  [grep, window, folk, used, unix, probably, fam...   \n",
       "9  [february, production, estimate, forwarded, ca...   \n",
       "\n",
       "                                              Vector  \n",
       "0  [1.6163436, 2.1998005, 0.84823847, -0.9715893,...  \n",
       "1  [1.0151408, 0.62459177, 0.26562575, -1.0730993...  \n",
       "2  [0.87613297, 0.3476915, 0.85935056, -0.5140939...  \n",
       "3  [2.1047955, 1.7402498, -0.3284932, 0.095167555...  \n",
       "4  [1.041842, 0.69830966, -1.3863869, -0.9889647,...  \n",
       "5  [1.4207256, 1.6403165, 0.9553901, -0.5626389, ...  \n",
       "6  [1.6428739, -0.11459401, -0.6236425, -1.565189...  \n",
       "7  [1.090038, 1.1250864, 1.4104717, 0.7268404, 0....  \n",
       "8  [2.1363153, 0.7653812, 0.08830727, -0.54238415...  \n",
       "9  [0.18950234, 0.67726636, 0.48134622, -1.469822...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing the data\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(txt):\n",
    "    tokens = word_tokenize(txt)\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens if t not in stop_words and t.isalnum()]\n",
    "    return tokens\n",
    "\n",
    "df['Preproc_txt'] = df['Body'].apply(preprocess)\n",
    "\n",
    "# creating tagged data\n",
    "tagged_data = [TaggedDocument(words=txt, tags=[i]) for i, txt in enumerate(df['Preproc_txt'])]\n",
    "\n",
    "# training a Doc2Vec model\n",
    "model = Doc2Vec(vector_size=50, window=3, min_count=1, workers=4, epochs=200, dm=0)\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# converting text data to vectors\n",
    "df['Vector'] = df['Preproc_txt'].apply(lambda x: model.infer_vector(x))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b1bb3e",
   "metadata": {},
   "source": [
    "### Splitting into Subsets (65%-15%-20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "608b879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 65% for training, 15% for validation, 20% for testing\n",
    "# extracting features(X) and labels(y)\n",
    "X = np.array(df['Vector'].tolist())\n",
    "y = np.array(df['Label'])\n",
    "\n",
    "# 1st split: splitting out the 65% for the training data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.35, random_state=0)\n",
    "\n",
    "# 2nd split: splitting out the 15% of the validation set from the remaining 35%\n",
    "val_test_ratio = (3/7) # (15/35)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=val_test_ratio, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2304989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in train subset:  13306 - 64.99609222352481  %\n",
      "Number of entries in val subset:  4094 - 19.998046111762406  %\n",
      "Number of entries in test subset:  3072 - 15.005861664712778  %\n"
     ]
    }
   ],
   "source": [
    "print('Number of entries in train subset: ', len(X_train), '-', ((len(X_train)*100)/(len(df))), ' %')\n",
    "print('Number of entries in val subset: ', len(X_val), '-', ((len(X_val)*100)/(len(df))), ' %')\n",
    "print('Number of entries in test subset: ', len(X_test), '-', ((len(X_test)*100)/(len(df))), ' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126401be",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "### Performance Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "317f198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(actual, pred):\n",
    "    print('Validation Confusion Matrix:')\n",
    "    print(confusion_matrix(actual, pred))\n",
    "    print('Validation Classification Report:')\n",
    "    print(classification_report(actual, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d028b3f6",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c703183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a wrapper for the neural network\n",
    "class Wrapper(BaseEstimator, ClassifierMixin):  \n",
    "    def __init__(self, build_fn=None, **kwargs):\n",
    "        self.build_fn = build_fn\n",
    "        self.kwargs = kwargs\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        if self.build_fn is None:\n",
    "            raise ValueError()\n",
    "        self.model = self.build_fn(**self.kwargs)\n",
    "        self.model.fit(X, y, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = self.model.predict(X)\n",
    "        return (predictions > 0.5).astype(int)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # getting probabilities for the positive class\n",
    "        probas = self.model.predict(X)\n",
    "        # concatenating with probabilities for the negative class\n",
    "        return np.hstack([1 - probas, probas])\n",
    "    \n",
    "def make_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(128, input_dim=50, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb355eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "832/832 [==============================] - 1s 979us/step - loss: 0.2558 - accuracy: 0.8912 - val_loss: 0.0974 - val_accuracy: 0.9648\n",
      "Epoch 2/5\n",
      "832/832 [==============================] - 1s 837us/step - loss: 0.1244 - accuracy: 0.9524 - val_loss: 0.0762 - val_accuracy: 0.9722\n",
      "Epoch 3/5\n",
      "832/832 [==============================] - 1s 820us/step - loss: 0.0998 - accuracy: 0.9629 - val_loss: 0.0717 - val_accuracy: 0.9731\n",
      "Epoch 4/5\n",
      "832/832 [==============================] - 1s 832us/step - loss: 0.0862 - accuracy: 0.9678 - val_loss: 0.0624 - val_accuracy: 0.9761\n",
      "Epoch 5/5\n",
      "832/832 [==============================] - 1s 860us/step - loss: 0.0762 - accuracy: 0.9711 - val_loss: 0.0595 - val_accuracy: 0.9766\n",
      "128/128 [==============================] - 0s 605us/step - loss: 0.0595 - accuracy: 0.9766\n",
      "Epoch 1/5\n",
      "416/416 [==============================] - 1s 1ms/step - loss: 0.2956 - accuracy: 0.8705 - val_loss: 0.1019 - val_accuracy: 0.9599\n",
      "Epoch 2/5\n",
      "416/416 [==============================] - 0s 899us/step - loss: 0.1423 - accuracy: 0.9478 - val_loss: 0.0879 - val_accuracy: 0.9663\n",
      "Epoch 3/5\n",
      "416/416 [==============================] - 0s 909us/step - loss: 0.1164 - accuracy: 0.9554 - val_loss: 0.0747 - val_accuracy: 0.9714\n",
      "Epoch 4/5\n",
      "416/416 [==============================] - 0s 912us/step - loss: 0.1027 - accuracy: 0.9619 - val_loss: 0.0684 - val_accuracy: 0.9729\n",
      "Epoch 5/5\n",
      "416/416 [==============================] - 0s 927us/step - loss: 0.0862 - accuracy: 0.9679 - val_loss: 0.0624 - val_accuracy: 0.9770\n",
      "128/128 [==============================] - 0s 494us/step - loss: 0.0624 - accuracy: 0.9770\n",
      "Epoch 1/5\n",
      "208/208 [==============================] - 1s 1ms/step - loss: 0.3709 - accuracy: 0.8308 - val_loss: 0.1092 - val_accuracy: 0.9595\n",
      "Epoch 2/5\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.1570 - accuracy: 0.9420 - val_loss: 0.0895 - val_accuracy: 0.9668\n",
      "Epoch 3/5\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.1259 - accuracy: 0.9519 - val_loss: 0.0794 - val_accuracy: 0.9712\n",
      "Epoch 4/5\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.9599 - val_loss: 0.0723 - val_accuracy: 0.9729\n",
      "Epoch 5/5\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9634 - val_loss: 0.0678 - val_accuracy: 0.9736\n",
      "128/128 [==============================] - 0s 466us/step - loss: 0.0678 - accuracy: 0.9736\n",
      "Epoch 1/8\n",
      "832/832 [==============================] - 1s 904us/step - loss: 0.2419 - accuracy: 0.8982 - val_loss: 0.0984 - val_accuracy: 0.9631\n",
      "Epoch 2/8\n",
      "832/832 [==============================] - 1s 879us/step - loss: 0.1283 - accuracy: 0.9520 - val_loss: 0.0848 - val_accuracy: 0.9668\n",
      "Epoch 3/8\n",
      "832/832 [==============================] - 1s 897us/step - loss: 0.1038 - accuracy: 0.9604 - val_loss: 0.0699 - val_accuracy: 0.9739\n",
      "Epoch 4/8\n",
      "832/832 [==============================] - 1s 851us/step - loss: 0.0909 - accuracy: 0.9669 - val_loss: 0.0657 - val_accuracy: 0.9753\n",
      "Epoch 5/8\n",
      "832/832 [==============================] - 1s 866us/step - loss: 0.0784 - accuracy: 0.9723 - val_loss: 0.0592 - val_accuracy: 0.9775\n",
      "Epoch 6/8\n",
      "832/832 [==============================] - 1s 825us/step - loss: 0.0722 - accuracy: 0.9738 - val_loss: 0.0588 - val_accuracy: 0.9795\n",
      "Epoch 7/8\n",
      "832/832 [==============================] - 1s 783us/step - loss: 0.0671 - accuracy: 0.9753 - val_loss: 0.0533 - val_accuracy: 0.9807\n",
      "Epoch 8/8\n",
      "832/832 [==============================] - 1s 830us/step - loss: 0.0589 - accuracy: 0.9786 - val_loss: 0.0559 - val_accuracy: 0.9797\n",
      "128/128 [==============================] - 0s 574us/step - loss: 0.0559 - accuracy: 0.9797\n",
      "Epoch 1/8\n",
      "416/416 [==============================] - 1s 1ms/step - loss: 0.2837 - accuracy: 0.8747 - val_loss: 0.0991 - val_accuracy: 0.9609\n",
      "Epoch 2/8\n",
      "416/416 [==============================] - 0s 977us/step - loss: 0.1348 - accuracy: 0.9504 - val_loss: 0.0844 - val_accuracy: 0.9675\n",
      "Epoch 3/8\n",
      "416/416 [==============================] - 0s 949us/step - loss: 0.1094 - accuracy: 0.9597 - val_loss: 0.0768 - val_accuracy: 0.9697\n",
      "Epoch 4/8\n",
      "416/416 [==============================] - 0s 900us/step - loss: 0.0933 - accuracy: 0.9654 - val_loss: 0.0670 - val_accuracy: 0.9734\n",
      "Epoch 5/8\n",
      "416/416 [==============================] - 0s 890us/step - loss: 0.0832 - accuracy: 0.9681 - val_loss: 0.0645 - val_accuracy: 0.9736\n",
      "Epoch 6/8\n",
      "416/416 [==============================] - 0s 931us/step - loss: 0.0743 - accuracy: 0.9728 - val_loss: 0.0573 - val_accuracy: 0.9775\n",
      "Epoch 7/8\n",
      "416/416 [==============================] - 0s 906us/step - loss: 0.0714 - accuracy: 0.9732 - val_loss: 0.0548 - val_accuracy: 0.9773\n",
      "Epoch 8/8\n",
      "416/416 [==============================] - 0s 914us/step - loss: 0.0684 - accuracy: 0.9746 - val_loss: 0.0549 - val_accuracy: 0.9766\n",
      "128/128 [==============================] - 0s 723us/step - loss: 0.0549 - accuracy: 0.9766\n",
      "Epoch 1/8\n",
      "208/208 [==============================] - 1s 1ms/step - loss: 0.3512 - accuracy: 0.8383 - val_loss: 0.1077 - val_accuracy: 0.9595\n",
      "Epoch 2/8\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.1544 - accuracy: 0.9410 - val_loss: 0.0918 - val_accuracy: 0.9653\n",
      "Epoch 3/8\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.9518 - val_loss: 0.0850 - val_accuracy: 0.9685\n",
      "Epoch 4/8\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.9584 - val_loss: 0.0760 - val_accuracy: 0.9719\n",
      "Epoch 5/8\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.0995 - accuracy: 0.9635 - val_loss: 0.0713 - val_accuracy: 0.9731\n",
      "Epoch 6/8\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.0883 - accuracy: 0.9680 - val_loss: 0.0642 - val_accuracy: 0.9766\n",
      "Epoch 7/8\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.0823 - accuracy: 0.9704 - val_loss: 0.0636 - val_accuracy: 0.9756\n",
      "Epoch 8/8\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.0740 - accuracy: 0.9711 - val_loss: 0.0640 - val_accuracy: 0.9756\n",
      "128/128 [==============================] - 0s 520us/step - loss: 0.0640 - accuracy: 0.9756\n",
      "Epoch 1/10\n",
      "832/832 [==============================] - 1s 936us/step - loss: 0.2524 - accuracy: 0.8960 - val_loss: 0.1027 - val_accuracy: 0.9609\n",
      "Epoch 2/10\n",
      "832/832 [==============================] - 1s 807us/step - loss: 0.1253 - accuracy: 0.9540 - val_loss: 0.0837 - val_accuracy: 0.9690\n",
      "Epoch 3/10\n",
      "832/832 [==============================] - 1s 848us/step - loss: 0.1029 - accuracy: 0.9627 - val_loss: 0.0684 - val_accuracy: 0.9748\n",
      "Epoch 4/10\n",
      "832/832 [==============================] - 1s 851us/step - loss: 0.0865 - accuracy: 0.9690 - val_loss: 0.0651 - val_accuracy: 0.9753\n",
      "Epoch 5/10\n",
      "832/832 [==============================] - 1s 839us/step - loss: 0.0762 - accuracy: 0.9714 - val_loss: 0.0576 - val_accuracy: 0.9787\n",
      "Epoch 6/10\n",
      "832/832 [==============================] - 1s 818us/step - loss: 0.0689 - accuracy: 0.9750 - val_loss: 0.0667 - val_accuracy: 0.9753\n",
      "Epoch 7/10\n",
      "832/832 [==============================] - 1s 852us/step - loss: 0.0647 - accuracy: 0.9759 - val_loss: 0.0547 - val_accuracy: 0.9807\n",
      "Epoch 8/10\n",
      "832/832 [==============================] - 1s 812us/step - loss: 0.0577 - accuracy: 0.9793 - val_loss: 0.0564 - val_accuracy: 0.9802\n",
      "Epoch 9/10\n",
      "832/832 [==============================] - 1s 863us/step - loss: 0.0539 - accuracy: 0.9799 - val_loss: 0.0569 - val_accuracy: 0.9807\n",
      "Epoch 10/10\n",
      "832/832 [==============================] - 1s 874us/step - loss: 0.0519 - accuracy: 0.9801 - val_loss: 0.0546 - val_accuracy: 0.9812\n",
      "128/128 [==============================] - 0s 468us/step - loss: 0.0546 - accuracy: 0.9812\n",
      "Epoch 1/10\n",
      "416/416 [==============================] - 1s 1ms/step - loss: 0.3145 - accuracy: 0.8570 - val_loss: 0.1031 - val_accuracy: 0.9614\n",
      "Epoch 2/10\n",
      "416/416 [==============================] - 0s 933us/step - loss: 0.1421 - accuracy: 0.9469 - val_loss: 0.0855 - val_accuracy: 0.9697\n",
      "Epoch 3/10\n",
      "416/416 [==============================] - 0s 924us/step - loss: 0.1115 - accuracy: 0.9594 - val_loss: 0.0728 - val_accuracy: 0.9739\n",
      "Epoch 4/10\n",
      "416/416 [==============================] - 0s 950us/step - loss: 0.0932 - accuracy: 0.9644 - val_loss: 0.0649 - val_accuracy: 0.9751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "416/416 [==============================] - 0s 985us/step - loss: 0.0826 - accuracy: 0.9700 - val_loss: 0.0636 - val_accuracy: 0.9768\n",
      "Epoch 6/10\n",
      "416/416 [==============================] - 0s 901us/step - loss: 0.0741 - accuracy: 0.9710 - val_loss: 0.0568 - val_accuracy: 0.9783\n",
      "Epoch 7/10\n",
      "416/416 [==============================] - 0s 916us/step - loss: 0.0733 - accuracy: 0.9723 - val_loss: 0.0551 - val_accuracy: 0.9780\n",
      "Epoch 8/10\n",
      "416/416 [==============================] - 0s 882us/step - loss: 0.0637 - accuracy: 0.9771 - val_loss: 0.0572 - val_accuracy: 0.9783\n",
      "Epoch 9/10\n",
      "416/416 [==============================] - 0s 938us/step - loss: 0.0585 - accuracy: 0.9776 - val_loss: 0.0531 - val_accuracy: 0.9809\n",
      "Epoch 10/10\n",
      "416/416 [==============================] - 0s 922us/step - loss: 0.0550 - accuracy: 0.9805 - val_loss: 0.0510 - val_accuracy: 0.9822\n",
      "128/128 [==============================] - 0s 637us/step - loss: 0.0510 - accuracy: 0.9822\n",
      "Epoch 1/10\n",
      "208/208 [==============================] - 1s 1ms/step - loss: 0.3395 - accuracy: 0.8458 - val_loss: 0.1138 - val_accuracy: 0.9560\n",
      "Epoch 2/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9415 - val_loss: 0.0928 - val_accuracy: 0.9624\n",
      "Epoch 3/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.1266 - accuracy: 0.9515 - val_loss: 0.0839 - val_accuracy: 0.9668\n",
      "Epoch 4/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.9589 - val_loss: 0.0787 - val_accuracy: 0.9697\n",
      "Epoch 5/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.1001 - accuracy: 0.9627 - val_loss: 0.0724 - val_accuracy: 0.9719\n",
      "Epoch 6/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.0901 - accuracy: 0.9671 - val_loss: 0.0672 - val_accuracy: 0.9744\n",
      "Epoch 7/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 0.9711 - val_loss: 0.0626 - val_accuracy: 0.9770\n",
      "Epoch 8/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.0729 - accuracy: 0.9735 - val_loss: 0.0596 - val_accuracy: 0.9773\n",
      "Epoch 9/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 0.9750 - val_loss: 0.0558 - val_accuracy: 0.9783\n",
      "Epoch 10/10\n",
      "208/208 [==============================] - 0s 1ms/step - loss: 0.0624 - accuracy: 0.9769 - val_loss: 0.0555 - val_accuracy: 0.9787\n",
      "128/128 [==============================] - 0s 437us/step - loss: 0.0555 - accuracy: 0.9787\n",
      "Epoch 1/10\n",
      "416/416 [==============================] - 1s 797us/step - loss: 0.2933 - accuracy: 0.8701\n",
      "Epoch 2/10\n",
      "416/416 [==============================] - 0s 779us/step - loss: 0.1392 - accuracy: 0.9481\n",
      "Epoch 3/10\n",
      "416/416 [==============================] - 0s 747us/step - loss: 0.1128 - accuracy: 0.9572\n",
      "Epoch 4/10\n",
      "416/416 [==============================] - 0s 770us/step - loss: 0.0986 - accuracy: 0.9636\n",
      "Epoch 5/10\n",
      "416/416 [==============================] - 0s 795us/step - loss: 0.0853 - accuracy: 0.9679\n",
      "Epoch 6/10\n",
      "416/416 [==============================] - 0s 774us/step - loss: 0.0796 - accuracy: 0.9720\n",
      "Epoch 7/10\n",
      "416/416 [==============================] - 0s 784us/step - loss: 0.0714 - accuracy: 0.9740\n",
      "Epoch 8/10\n",
      "416/416 [==============================] - 0s 778us/step - loss: 0.0659 - accuracy: 0.9761\n",
      "Epoch 9/10\n",
      "416/416 [==============================] - 0s 804us/step - loss: 0.0606 - accuracy: 0.9781\n",
      "Epoch 10/10\n",
      "416/416 [==============================] - 0s 769us/step - loss: 0.0582 - accuracy: 0.9786\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Wrapper(build_fn=&lt;function make_model at 0x7f9db3df9ab0&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Wrapper</label><div class=\"sk-toggleable__content\"><pre>Wrapper(build_fn=&lt;function make_model at 0x7f9db3df9ab0&gt;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Wrapper(build_fn=<function make_model at 0x7f9db3df9ab0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tuning the hyperparameters\n",
    "best_accuracy = 0\n",
    "best_params_nn = None\n",
    "\n",
    "for epochs in [5, 8, 10]:\n",
    "    for batch_size in [16, 32, 64]:\n",
    "        nn = Wrapper(build_fn=make_model)\n",
    "        nn.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
    "        \n",
    "        # evaluating on the validation set\n",
    "        loss, accuracy = nn.model.evaluate(X_val, y_val)\n",
    "\n",
    "        # updating best hyperparameters\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params_nn = {'epochs': epochs, 'batch_size': batch_size}\n",
    "\n",
    "# training final model with best hyperparameters\n",
    "best_nn = Wrapper(build_fn=make_model)\n",
    "best_nn.fit(X_train, y_train, epochs=best_params_nn['epochs'], batch_size=best_params_nn['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b30808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'epochs': 10, 'batch_size': 32}\n",
      "128/128 [==============================] - 0s 514us/step\n",
      "Validation Confusion Matrix:\n",
      "[[2577   38]\n",
      " [  30 1449]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      2615\n",
      "           1       0.97      0.98      0.98      1479\n",
      "\n",
      "    accuracy                           0.98      4094\n",
      "   macro avg       0.98      0.98      0.98      4094\n",
      "weighted avg       0.98      0.98      0.98      4094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters:', best_params_nn)\n",
    "\n",
    "# evaluating the model\n",
    "y_val_pred_nn = best_nn.predict(X_val)\n",
    "get_performance(y_val, y_val_pred_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2abe1f2",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a8ffffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Validation Confusion Matrix:\n",
      "[[2563   52]\n",
      " [ 138 1341]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      2615\n",
      "           1       0.96      0.91      0.93      1479\n",
      "\n",
      "    accuracy                           0.95      4094\n",
      "   macro avg       0.96      0.94      0.95      4094\n",
      "weighted avg       0.95      0.95      0.95      4094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating a Random Forest model\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# defining parameter grid\n",
    "params_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# grid search for the best hyperparameters\n",
    "grid_search_rf = GridSearchCV(estimator=rf, param_grid=params_rf, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search_rf.fit(X_val, y_val)\n",
    "print('Best Parameters:', grid_search_rf.best_params_)\n",
    "\n",
    "# creating the best rf model\n",
    "best_rf = RandomForestClassifier(random_state=0, **grid_search_rf.best_params_)\n",
    "best_rf.fit(X_train, y_train)\n",
    "y_val_pred_rf = best_rf.predict(X_val)\n",
    "get_performance(y_val, y_val_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6842544c",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89706f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Parameters: {'C': 1, 'penalty': 'l2'}\n",
      "Validation Confusion Matrix:\n",
      "[[2526   89]\n",
      " [  89 1390]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      2615\n",
      "           1       0.94      0.94      0.94      1479\n",
      "\n",
      "    accuracy                           0.96      4094\n",
      "   macro avg       0.95      0.95      0.95      4094\n",
      "weighted avg       0.96      0.96      0.96      4094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating a Logistic Regression model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# defining parameter grid\n",
    "params_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # regularization strength\n",
    "    'penalty': ['l2'],  # regularization type\n",
    "}\n",
    "\n",
    "# grid search for the best parameters\n",
    "grid_search_lr = GridSearchCV(lr, params_lr, cv=5, scoring='accuracy', verbose=1)\n",
    "grid_search_lr.fit(X_val, y_val)\n",
    "print('Best Parameters:', grid_search_lr.best_params_)\n",
    "\n",
    "# creating the best lr model\n",
    "best_lr = LogisticRegression(**grid_search_lr.best_params_)\n",
    "best_lr.fit(X_train, y_train)\n",
    "y_val_pred_lr = best_lr.predict(X_val)\n",
    "get_performance(y_val, y_val_pred_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d08ce88",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "006bc781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.5s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.5s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.5s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.5s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.5s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.5s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.3s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.3s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.3s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.3s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.3s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.2s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   2.0s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   1.8s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   1.7s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   2.0s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   1.7s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   1.4s\n",
      "Best Parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Validation Confusion Matrix:\n",
      "[[2569   46]\n",
      " [  26 1453]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      2615\n",
      "           1       0.97      0.98      0.98      1479\n",
      "\n",
      "    accuracy                           0.98      4094\n",
      "   macro avg       0.98      0.98      0.98      4094\n",
      "weighted avg       0.98      0.98      0.98      4094\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating an SVC model\n",
    "svc = SVC(probability=True)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# defining parameter grid\n",
    "params_svc = {\n",
    "    'C': [0.1, 1, 10],  # Example parameters, adjust according to your needs\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['rbf', 'linear']  # Example kernels, adjust as needed\n",
    "}\n",
    "\n",
    "# grid search for the best parameters\n",
    "grid_search_svc = GridSearchCV(SVC(probability=True), params_svc, cv=3, scoring='accuracy', verbose=2)\n",
    "grid_search_svc.fit(X_val, y_val)\n",
    "print('Best Parameters:', grid_search_svc.best_params_)\n",
    "\n",
    "# creating the best svc model\n",
    "best_svc = SVC(probability=True, **grid_search_svc.best_params_)\n",
    "best_svc.fit(X_train, y_train)\n",
    "y_val_pred_svc = best_svc.predict(X_val)\n",
    "get_performance(y_val, y_val_pred_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6028c899",
   "metadata": {},
   "source": [
    "### Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1316973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416/416 [==============================] - 1s 759us/step - loss: 0.2965 - accuracy: 0.8690\n",
      "96/96 [==============================] - 0s 497us/step\n",
      "Validation Confusion Matrix:\n",
      "[[1882   27]\n",
      " [  70 1093]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1909\n",
      "           1       0.98      0.94      0.96      1163\n",
      "\n",
      "    accuracy                           0.97      3072\n",
      "   macro avg       0.97      0.96      0.97      3072\n",
      "weighted avg       0.97      0.97      0.97      3072\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating ensemble model\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('nn', best_nn), \n",
    "    ('rf', best_rf), \n",
    "    ('lr', best_lr), \n",
    "    ('svc', best_svc)\n",
    "], voting='soft')\n",
    "\n",
    "# training ensemble model\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# predicting probabilities for each class\n",
    "probabilities = ensemble_model.predict_proba(X_test)\n",
    "\n",
    "# adjusting the threshold to increase recall for class '0' (less valid emails classified as spam)\n",
    "threshold = 0.4  # Example threshold, adjust based on your needs\n",
    "y_test_pred_ensemble = np.where(probabilities[:, 0] >= threshold, 0, 1)\n",
    "\n",
    "# evaluation with the threshold\n",
    "get_performance(y_test, y_test_pred_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611d353c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
